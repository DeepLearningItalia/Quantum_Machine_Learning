{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Binary Classifier on a Quantum Computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the practical part related to the lecture: Practice 1 - Training a Quantum Binary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dwave-ocean-sdk\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/6a/1eb9a56afce8da49eb5eb165f086d80f9c87c60d505176751ef83a05fd6a/dwave_ocean_sdk-3.1.1-py3-none-any.whl\n",
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/21/f72ec478fba7db3a4ab7a57867115a7275e48015adacb33caae2dad96f63/numpy-1.19.4-cp36-cp36m-macosx_10_9_x86_64.whl (15.3MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3MB 16.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/47/c7/348acee81b0cf8eec66b4a71c8cca188f405061cb76cc3f9f72249568a22/scipy-1.5.4-cp36-cp36m-macosx_10_9_x86_64.whl (28.8MB)\n",
      "\u001b[K     |████████████████████████████████| 28.8MB 16.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Using cached https://files.pythonhosted.org/packages/d9/78/44fb6f0842e93d401040cc06db1a9787c9c16df15c8970cdc8999587a322/scikit_learn-0.23.2-cp36-cp36m-macosx_10_9_x86_64.whl\n",
      "Collecting sklearn\n",
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/a5/2bfd885118ebec3e3efdfe3527189b1857285006dca31dc408edbacfa226/pandas-1.1.4-cp36-cp36m-macosx_10_9_x86_64.whl (10.2MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2MB 12.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dwave-hybrid==0.6.0 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/42/914cb7bb767303f0862dd50074b03c4c184ac513e2ee5bb437e4ce1e7f42/dwave_hybrid-0.6.0-py3-none-any.whl (93kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 10.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting dwave-neal==0.5.6 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/43/a2a4b5c31a870d28b682a26b185e740a6bfcad195648552d4e3a3d6b0f97/dwave_neal-0.5.6-cp36-cp36m-macosx_10_9_x86_64.whl (95kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 10.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting dimod==0.9.10 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/c4/f79a1704a59d177b0305fc02a633272c4e3d670a1b06105f11a4aca45877/dimod-0.9.10-cp36-cp36m-macosx_10_9_x86_64.whl (2.4MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4MB 14.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting penaltymodel-cache==0.4.1 (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/c5/3cb25828105a8b5e4b181cb94d23593f44cfca71c4e1247a6a631dca3dd2/penaltymodel_cache-0.4.1-py3-none-any.whl\n",
      "Collecting penaltymodel-lp==0.1.3 (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/86/4c4c4de17c7e45f1958547da6a3fe866b6a6f48bf4785575bf6cc9ab91ca/penaltymodel_lp-0.1.3-py3-none-any.whl\n",
      "Collecting minorminer==0.2.3 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/0a/39424d54175cc766d0d369449373113dfb33356411da202d1cb47b9bc7a1/minorminer-0.2.3-cp36-cp36m-macosx_10_15_x86_64.whl (468kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 15.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dwave-inspector==0.2.4 (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/40/b5/7acfc0c7c4684bee6beeceb59c17c1fdec4562cc2f7731ad6004cb771cc3/dwave_inspector-0.2.4-py3-none-any.whl\n",
      "Collecting dwave-networkx==0.8.8 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/51/feeaa00ae0ccfb6a56731d917f998bc9606f0db2a9719b9b4947a206defc/dwave_networkx-0.8.8-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 8.9MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting dwave-greedy==0.1.1 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/09/146e4df7dc2f093331c25a41db6be3c84a1f38c4ff3893aa7ef55cfed21e/dwave_greedy-0.1.1-cp36-cp36m-macosx_10_9_x86_64.whl (93kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 13.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting dwave-tabu==0.3.0 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/83/ba79b4a6111e096213fad7d48d9eddab4d6f600b6642e1f87670bc47fc16/dwave_tabu-0.3.0-cp36-cp36m-macosx_10_9_x86_64.whl (163kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 15.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting penaltymodel==0.16.3 (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/1d/d114fe1c401719964fbf404c2c25113edb994df9f93c5773c19da406d192/penaltymodel-0.16.3-py3-none-any.whl\n",
      "Collecting penaltymodel-mip==0.2.3; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\" (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/f5/fa3cc200983692675fdb07c57d6e28ee0b07a98e7ec0955f4d45ab7c4764/penaltymodel_mip-0.2.3-py3-none-any.whl\n",
      "Collecting dwave-cloud-client==0.8.1 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/39/1d11501f3cacffa868ba0a0991bdba82ee4a999e22e71f6fea046796fcfd/dwave_cloud_client-0.8.1-py3-none-any.whl (85kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 12.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dwave-qbsolv==0.3.1 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/98/a76ed56410b8ad1bb07091833b02be3248ad5feae4fba2342c60c3d34ce7/dwave_qbsolv-0.3.1-cp36-cp36m-macosx_10_9_x86_64.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 12.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyqubo==0.4.0 (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/28/57/ba41de3b13ba23e981463aa1daa2ebe6bd9dcddb15571e4c5905463326c7/pyqubo-0.4.0.tar.gz\n",
      "Collecting dwavebinarycsp==0.1.2 (from dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/f2/8422100bfa1a9cce5c0f3ca8b088a3d1f46582c0085adb2db09837dbc0f1/dwavebinarycsp-0.1.2-py3-none-any.whl\n",
      "Collecting dwave-system==1.2.1 (from dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/aa/e27f5681fe955405562991843379be5021b8e248a15ee21be8d7fb4d709e/dwave_system-1.2.1-py3-none-any.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 6.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn)\n",
      "  Using cached https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 17.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Collecting networkx (from dwave-hybrid==0.6.0->dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/cd/dc52755d30ba41c60243235460961fc28022e5b6731f16c268667625baea/networkx-2.5-py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 8.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plucky>=0.4.3 (from dwave-hybrid==0.6.0->dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/70/7b43e7280284bafecb345f4edb3eea7042cf0d089c5d112920eda650fda5/plucky-0.4.3-py2.py3-none-any.whl\n",
      "Collecting click>5 (from dwave-hybrid==0.6.0->dwave-ocean-sdk)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six<2.0.0,>=1.11.0 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from penaltymodel-cache==0.4.1->dwave-ocean-sdk) (1.15.0)\n",
      "Collecting homebase<2.0.0,>=1.0.0 (from penaltymodel-cache==0.4.1->dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/50/ad/e0080c35bd177682d5118a95bc2e7c1ac0541394b4ffce5e9554b6a077f9/homebase-1.0.1-py2.py3-none-any.whl\n",
      "Collecting fasteners (from minorminer==0.2.3->dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/18/bd/55eb2d6397b9c0e263af9d091ebdb756b15756029b3cededf6461481bc63/fasteners-0.15-py2.py3-none-any.whl\n",
      "Collecting importlib-resources; python_version < \"3.7\" (from dwave-inspector==0.2.4->dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/1f/ec86d2a5c48ac6490d4471b297885603cf0e8da89d5ffbf0bce6e57f4d64/importlib_resources-3.3.0-py2.py3-none-any.whl\n",
      "Collecting Flask>=1.1.1 (from dwave-inspector==0.2.4->dwave-ocean-sdk)\n",
      "  Using cached https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator<5.0.0,>=4.1.0 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from dwave-networkx==0.8.8->dwave-ocean-sdk) (4.4.2)\n",
      "Collecting ortools<8.0.0,>=6.6.4659 (from penaltymodel-mip==0.2.3; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\"->dwave-ocean-sdk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/89/6bf5d62fc3b42d4bcce72a0bee0739ae1420770483c4b199a47589708e2d/ortools-7.8.7959-cp36-cp36m-macosx_10_6_intel.whl (28.3MB)\n",
      "\u001b[K     |████████████████████████████████| 28.3MB 2.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests[socks]>=2.18 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from dwave-cloud-client==0.8.1->dwave-ocean-sdk) (2.24.0)\n",
      "Collecting monotonic>=0.1 (from fasteners->minorminer==0.2.3->dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from importlib-resources; python_version < \"3.7\"->dwave-inspector==0.2.4->dwave-ocean-sdk) (3.4.0)\n",
      "Collecting itsdangerous>=0.24 (from Flask>=1.1.1->dwave-inspector==0.2.4->dwave-ocean-sdk)\n",
      "  Using cached https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Werkzeug>=0.15 (from Flask>=1.1.1->dwave-inspector==0.2.4->dwave-ocean-sdk)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from Flask>=1.1.1->dwave-inspector==0.2.4->dwave-ocean-sdk) (2.11.2)\n",
      "Collecting protobuf>=3.12.2 (from ortools<8.0.0,>=6.6.4659->penaltymodel-mip==0.2.3; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\"->dwave-ocean-sdk)\n",
      "  Using cached https://files.pythonhosted.org/packages/ec/86/eec5df8bc917e22e96e0e8e2762a6772397624fad3a7a0da5913e11490db/protobuf-3.13.0-cp36-cp36m-macosx_10_9_x86_64.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from requests[socks]>=2.18->dwave-cloud-client==0.8.1->dwave-ocean-sdk) (2018.1.18)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from requests[socks]>=2.18->dwave-cloud-client==0.8.1->dwave-ocean-sdk) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from requests[socks]>=2.18->dwave-cloud-client==0.8.1->dwave-ocean-sdk) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from requests[socks]>=2.18->dwave-cloud-client==0.8.1->dwave-ocean-sdk) (1.25.11)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6; extra == \"socks\" (from requests[socks]>=2.18->dwave-cloud-client==0.8.1->dwave-ocean-sdk)\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from Jinja2>=2.10.1->Flask>=1.1.1->dwave-inspector==0.2.4->dwave-ocean-sdk) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /Users/zarbo/miniconda3/envs/qml/lib/python3.6/site-packages (from protobuf>=3.12.2->ortools<8.0.0,>=6.6.4659->penaltymodel-mip==0.2.3; platform_machine == \"x86_64\" or platform_machine == \"amd64\" or platform_machine == \"AMD64\"->dwave-ocean-sdk) (41.0.1.post20190818)\n",
      "Building wheels for collected packages: pyqubo\n",
      "  Building wheel for pyqubo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/zarbo/Library/Caches/pip/wheels/77/b7/47/b989889699f788f4fecdc534bfddbb16df9a9a51f4e431b04d\n",
      "Successfully built pyqubo\n",
      "Installing collected packages: numpy, dimod, networkx, dwave-networkx, plucky, dwave-tabu, dwave-greedy, dwave-neal, homebase, scipy, monotonic, fasteners, minorminer, click, dwave-cloud-client, dwave-system, dwave-hybrid, penaltymodel, penaltymodel-cache, penaltymodel-lp, importlib-resources, itsdangerous, Werkzeug, Flask, dwave-inspector, protobuf, ortools, penaltymodel-mip, dwave-qbsolv, pyqubo, dwavebinarycsp, dwave-ocean-sdk, joblib, threadpoolctl, scikit-learn, sklearn, pytz, pandas, PySocks\n",
      "Successfully installed Flask-1.1.2 PySocks-1.7.1 Werkzeug-1.0.1 click-7.1.2 dimod-0.9.10 dwave-cloud-client-0.8.1 dwave-greedy-0.1.1 dwave-hybrid-0.6.0 dwave-inspector-0.2.4 dwave-neal-0.5.6 dwave-networkx-0.8.8 dwave-ocean-sdk-3.1.1 dwave-qbsolv-0.3.1 dwave-system-1.2.1 dwave-tabu-0.3.0 dwavebinarycsp-0.1.2 fasteners-0.15 homebase-1.0.1 importlib-resources-3.3.0 itsdangerous-1.1.0 joblib-0.17.0 minorminer-0.2.3 monotonic-1.5 networkx-2.5 numpy-1.19.4 ortools-7.8.7959 pandas-1.1.4 penaltymodel-0.16.3 penaltymodel-cache-0.4.1 penaltymodel-lp-0.1.3 penaltymodel-mip-0.2.3 plucky-0.4.3 protobuf-3.13.0 pyqubo-0.4.0 pytz-2020.4 scikit-learn-0.23.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install dwave-ocean-sdk numpy scipy scikit-learn sklearn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QBoost Python Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imoports\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows how to create WeakClassifiers, where every feature of the sample is a DecisionTree.\n",
    "This class is capable of learning alone how to weight properly each feature in a standard classical way, we can see this in the *fit* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifiers(object):\n",
    "    \"\"\"\n",
    "    Weak Classifiers based on DecisionTree\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=50, max_depth=3):\n",
    "        self.n_estimators = n_estimators # this is the number of features\n",
    "        self.estimators_ = [] # here we will allocate every decision tree representing our feature\n",
    "        self.max_depth = max_depth # the maximum depth of our decision trees\n",
    "        self.__construct_wc() # here we create practically the trees representing our features\n",
    "\n",
    "    def __construct_wc(self):\n",
    "        # creation of the trees, one for each feature aka estimator\n",
    "        self.estimators_ = [DecisionTreeClassifier(max_depth=self.max_depth,\n",
    "                                                   random_state=np.random.randint(1000000,10000000))\n",
    "                            for _ in range(self.n_estimators)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        fit estimators\n",
    "        :param X:\n",
    "        :param y:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimator_weights = np.zeros(self.n_estimators)\n",
    "\n",
    "        d = np.ones(len(X)) / len(X)\n",
    "        for i, h in enumerate(self.estimators_):\n",
    "            h.fit(X, y, sample_weight=d) # here we fit the estimator \n",
    "            pred = h.predict(X) # predicting the y\n",
    "            eps = d.dot(pred != y) # checking the error\n",
    "            if eps == 0: # to prevent divided by zero error\n",
    "                eps = 1e-20\n",
    "            w = (np.log(1 - eps) - np.log(eps)) / 2 # calibration of the feature weight \n",
    "            d = d * np.exp(- w * y * pred) # calibration of the sample weight\n",
    "            d = d / d.sum()\n",
    "            self.estimator_weights[i] = w\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict label of X\n",
    "        :param X:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not hasattr(self, 'estimator_weights'):\n",
    "            raise Exception('Not Fitted Error!')\n",
    "\n",
    "        y = np.zeros(len(X))\n",
    "        \n",
    "        # As seen in the lecture our predicted label is the most voted by our estimators\n",
    "        for (h, w) in zip(self.estimators_, self.estimator_weights):\n",
    "            y += w * h.predict(X) # we sum the class vote for each estimator, using the fitted weight to get rid of the useless features\n",
    "\n",
    "        y = np.sign(y) # here we get the final call\n",
    "\n",
    "        return y\n",
    "\n",
    "    def copy(self):\n",
    "\n",
    "        classifier = WeakClassifiers(n_estimators=self.n_estimators, max_depth=self.max_depth)\n",
    "        classifier.estimators_ = deepcopy(self.estimators_)\n",
    "        if hasattr(self, 'estimator_weights'):\n",
    "            classifier.estimator_weights = np.array(self.estimator_weights)\n",
    "\n",
    "        return classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create QBoost classifier as a QUBO problem. \n",
    "The implementation if very similar than the above, but the assignment of the weights is the combinatorial part that we are going to compute quantumly.\n",
    "Starting from the weak classifier, by modelling our features as decision trees, we extend the fit and predict function in order to get advantage from the D-Wave quantum annealer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QBoostClassifier(WeakClassifiers):\n",
    "    \"\"\"\n",
    "    Qboost Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=50, max_depth=3):\n",
    "        # contruction of the QBoost Classifier as a Weak Classifier\n",
    "        super(QBoostClassifier, self).__init__(n_estimators=n_estimators,\n",
    "                                              max_depth=max_depth)\n",
    "\n",
    "    def fit(self, X, y, sampler, lmd=0.2, **kwargs):\n",
    "\n",
    "        n_data = len(X)\n",
    "\n",
    "        # step 1: fit weak classifiers\n",
    "        super(QBoostClassifier, self).fit(X, y)\n",
    "\n",
    "        # step 2: create QUBO\n",
    "        hij = []\n",
    "        for h in self.estimators_:\n",
    "            hij.append(h.predict(X))\n",
    "\n",
    "        hij = np.array(hij)\n",
    "        # scale hij to [-1/N, 1/N]\n",
    "        hij = 1. * hij / self.n_estimators\n",
    "\n",
    "        ## Create QUBO\n",
    "        qii = n_data * 1. / (self.n_estimators ** 2) + lmd - 2 * np.dot(hij, y) # This is formulae we saw at the lecture\n",
    "        qij = np.dot(hij, hij.T) # and this is the correlation term we say at the lecture\n",
    "        \n",
    "        # In the section below we are going to create a dictionary containing our variables and their relations in order\n",
    "        # to let the quantum annealer embed properly our problem and in such a way all the variables that should be connected\n",
    "        # each other will be, namely qij.\n",
    "        Q = dict()\n",
    "        Q.update(dict(((k, k), v) for (k, v) in enumerate(qii)))\n",
    "        for i in range(self.n_estimators):\n",
    "            for j in range(i + 1, self.n_estimators):\n",
    "                Q[(i, j)] = qij[i, j]\n",
    "\n",
    "        # step 3: optimize QUBO\n",
    "        # Here we let the problem anneal and we get out the best weight for each estimator\n",
    "        res = sampler.sample_qubo(Q, **kwargs)\n",
    "        samples = np.array([[samp[k] for k in range(self.n_estimators)] for samp in res])\n",
    "\n",
    "        # take the optimal solution as estimator weights\n",
    "        self.estimator_weights = samples[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_data = len(X)\n",
    "        pred_all = np.array([h.predict(X) for h in self.estimators_])\n",
    "        temp1 = np.dot(self.estimator_weights, pred_all)\n",
    "        T1 = np.sum(temp1, axis=0) / (n_data * self.n_estimators * 1.)\n",
    "        y = np.sign(temp1 - T1) #binary classes are either 1 or -1\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "# import necessary packages\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from dwave.system.samplers import DWaveSampler\n",
    "from dwave.system.composites import EmbeddingComposite\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = './'\n",
    "\n",
    "input_path = prefix + 'data'\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "\n",
    "# This algorithm has a single channel of input data called 'training'. Since we run in\n",
    "# File mode, the input files are copied to the directory specified here.\n",
    "training_file = os.path.join(input_path, 'training', 'train_wisc_binary.csv')\n",
    "test_file = os.path.join(input_path, 'test', 'test_wisc_binary.csv')\n",
    "\n",
    "# Define the functions required in this example\n",
    "def metric(y, y_pred):\n",
    "    \"\"\"\n",
    "    :param y: true label\n",
    "    :param y_pred: predicted label\n",
    "    :return: metric score\n",
    "    \"\"\"\n",
    "\n",
    "    return metrics.accuracy_score(y, y_pred)\n",
    "\n",
    "# Read in any hyperparameters that the user passed with the training job\n",
    "trainingParams = {\n",
    "    'lmd': 1.0,\n",
    "    'num_reads': 1000\n",
    "}\n",
    "\n",
    "# Take the set of files and read them all into a single pandas dataframe    \n",
    "train_data = pd.read_csv(training_file, header=None)\n",
    "test_data = pd.read_csv(test_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels are in the first column\n",
    "y_train = np.array(train_data.values[:,0]) # extract label\n",
    "y_train = 2 * y_train - 1 # -1, 1\n",
    "X_train = np.array(train_data.values[:,1:]) # extract data\n",
    "\n",
    "y_test = np.array(test_data.values[:,0])\n",
    "y_test = 2 * y_test - 1\n",
    "X_test = np.array(test_data.values[:,1:])\n",
    "\n",
    "# Here we only support a single hyperparameter. Note that hyperparameters are always passed in as\n",
    "# strings, so we need to do any necessary conversions.\n",
    "lmd = trainingParams.get('lmd', 1.0)\n",
    "if lmd is not None:\n",
    "    lmd = float(lmd)\n",
    "# define parameters used in this function\n",
    "NUM_READS = trainingParams.get('num_reads', 1000)\n",
    "if NUM_READS != 1000:\n",
    "    NUM_READS = int(NUM_READS)\n",
    "NUM_WEAK_CLASSIFIERS = X_train.shape[1]#\n",
    "TREE_DEPTH = trainingParams.get('tree_depth', 2)\n",
    "if TREE_DEPTH != 2:\n",
    "    TREE_DEPTH = int(TREE_DEPTH)\n",
    "\n",
    "DW_PARAMS = {'num_reads': NUM_READS,\n",
    "            'auto_scale': True,\n",
    "            'num_spin_reversal_transforms': 10,\n",
    "            'postprocess': 'optimization',\n",
    "            }\n",
    "\n",
    "\n",
    "DW_ENDPOINT = trainingParams.get('DW_ENDPOINT', 'https://cloud.dwavesys.com/sapi')\n",
    "DW_TOKEN = trainingParams.get('DW_TOKEN', None)\n",
    "DW_SLOVER = trainingParams.get('DW_SOLVER', 'DW_2000Q_6')\n",
    "\n",
    "if DW_ENDPOINT is None:\n",
    "    raise Exception('You need to put your token in the Env Variable: DW_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================\n",
      "Train size: 379\n",
      "Num weak classifiers: 30\n"
     ]
    }
   ],
   "source": [
    "# define sampler\n",
    "dwave_sampler = DWaveSampler(endpoint=DW_ENDPOINT, token=DW_TOKEN, solver=DW_SLOVER)\n",
    "emb_sampler = EmbeddingComposite(dwave_sampler)\n",
    "\n",
    "N_train = len(X_train)\n",
    "\n",
    "print(\"\\n======================================\")\n",
    "print(\"Train size: %d\" %(N_train))\n",
    "print('Num weak classifiers:', NUM_WEAK_CLASSIFIERS)\n",
    "\n",
    "# Preprocessing data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QBoost\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Qboost\n",
    "print('\\nQBoost')\n",
    "clf = QBoostClassifier(n_estimators=NUM_WEAK_CLASSIFIERS, max_depth=TREE_DEPTH)\n",
    "clf.fit(X_train, y_train, emb_sampler, lmd=lmd, **DW_PARAMS)\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting inference.\n",
      "Estimator weights: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "accu (test):  0.96\n"
     ]
    }
   ],
   "source": [
    "print('Starting inference.')\n",
    "y_test_prd = clf.predict(X_test)\n",
    "print('Estimator weights:',clf.estimator_weights)\n",
    "print('accu (test): %5.2f' % (metric(y_test, y_test_prd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "with open(os.path.join(model_path, 'qboost-model.pkl'), 'wb') as out:\n",
    "    pickle.dump(clf, out)\n",
    "print('Model saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark against classical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest\n",
      "accu (test):  0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest\")\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_test_prd_rf = rf_clf.predict(X_test)\n",
    "print('accu (test): %5.2f' % (metric(y_test, y_test_prd_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trovare un problema che faccia vedere Time to Solution advantage - Real Time application\n",
    "# Grafico di confronto - slide di D-Wave come esempio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
